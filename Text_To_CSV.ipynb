{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e046a678-823e-4af1-9376-ded0d71a240c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV conversion complete. 'output.csv' has been created.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "\n",
    "rows = []\n",
    "table_started = False\n",
    "expected_columns = None\n",
    "short_text_index = None\n",
    "\n",
    "with open(\"3. EKPO - Mar'24.txt\", \"r\", encoding=\"utf-8\", errors=\"replace\") as infile:\n",
    "    for line in infile:\n",
    "        line_stripped = line.strip()\n",
    "        # Skip lines that are empty or contain only dashes/spaces\n",
    "        if not line_stripped or re.fullmatch(r'[-\\s]+', line_stripped):\n",
    "            continue\n",
    "\n",
    "        # Check for the table header. We assume the header contains \"Purch.Doc.\"\n",
    "        if \"Purch.Doc.\" in line_stripped:\n",
    "            table_started = True\n",
    "            # Split on pipe or tab if pipe is not present\n",
    "            if \"|\" in line_stripped:\n",
    "                header = [field.strip() for field in line_stripped.split('|')]\n",
    "            else:\n",
    "                header = [field.strip() for field in re.split(r'\\t+', line_stripped)]\n",
    "            # Remove leading empty element if exists\n",
    "            if header and header[0] == \"\":\n",
    "                header = header[1:]\n",
    "            rows.append(header)\n",
    "            expected_columns = len(header)\n",
    "            # Determine the index for \"Short Text\" (if it exists)\n",
    "            try:\n",
    "                short_text_index = header.index(\"Short Text\")\n",
    "            except ValueError:\n",
    "                short_text_index = None\n",
    "            continue\n",
    "\n",
    "        # If the table has started, process subsequent lines as table data\n",
    "        if table_started:\n",
    "            if \"|\" in line_stripped:\n",
    "                row = [field.strip() for field in line_stripped.split('|')]\n",
    "            else:\n",
    "                row = [field.strip() for field in re.split(r'\\t+', line_stripped)]\n",
    "            # Remove leading empty element if exists\n",
    "            if row and row[0] == \"\":\n",
    "                row = row[1:]\n",
    "            # If we have a header and the \"Short Text\" column, and there are extra fields,\n",
    "            # combine extra fields into the \"Short Text\" column.\n",
    "            if expected_columns and short_text_index is not None and len(row) > expected_columns:\n",
    "                extra = len(row) - expected_columns\n",
    "                # Combine the fields that belong to \"Short Text\"\n",
    "                combined = \"|\".join(row[short_text_index:short_text_index + extra + 1])\n",
    "                # Build the new row: before Short Text, then combined field, then the rest\n",
    "                row = row[:short_text_index] + [combined] + row[short_text_index + extra + 1:]\n",
    "            \n",
    "            # Only add the row if it contains data\n",
    "            if row and any(field for field in row):\n",
    "                rows.append(row)\n",
    "\n",
    "with open(\"EKPO_Mar24.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as outfile:\n",
    "    writer = csv.writer(outfile)\n",
    "    writer.writerows(rows)\n",
    "\n",
    "print(\"CSV conversion complete. 'output.csv' has been created.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630a7e65-8753-4e10-996c-ec8de15ae20a",
   "metadata": {},
   "source": [
    "### For Converting text to csv without Duplicate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "54e2e1f7-bec6-433f-81cd-91f68d74bf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same code as above, but it is for converting text to csv without duplicate columns\n",
    "import csv\n",
    "import re\n",
    "\n",
    "rows = []\n",
    "table_started = False\n",
    "expected_columns = None\n",
    "short_text_index = None\n",
    "\n",
    "with open(\"1. EKPO - Jan'24.txt\", \"r\", encoding=\"utf-8\", errors=\"replace\") as infile:\n",
    "    for line in infile:\n",
    "        line_stripped = line.strip()\n",
    "        # Skip lines that are empty or contain only dashes/spaces\n",
    "        if not line_stripped or re.fullmatch(r'[-\\s]+', line_stripped):\n",
    "            continue\n",
    "\n",
    "        # Check for the table header. We assume the header contains \"Purch.Doc.\"\n",
    "        if \"Purch.Doc.\" in line_stripped:\n",
    "            table_started = True\n",
    "            # Split on pipe or on tab if pipe is not present\n",
    "            if \"|\" in line_stripped:\n",
    "                header = [field.strip() for field in line_stripped.split('|')]\n",
    "            else:\n",
    "                header = [field.strip() for field in re.split(r'\\t+', line_stripped)]\n",
    "            # Remove leading empty element if exists\n",
    "            if header and header[0] == \"\":\n",
    "                header = header[1:]\n",
    "            rows.append(header)\n",
    "            expected_columns = len(header)\n",
    "            # Determine the index for \"Short Text\" (if it exists)\n",
    "            try:\n",
    "                short_text_index = header.index(\"Short Text\")\n",
    "            except ValueError:\n",
    "                short_text_index = None\n",
    "            continue\n",
    "\n",
    "        # If the table has started, process subsequent lines as table data\n",
    "        if table_started:\n",
    "            if \"|\" in line_stripped:\n",
    "                row = [field.strip() for field in line_stripped.split('|')]\n",
    "            else:\n",
    "                row = [field.strip() for field in re.split(r'\\t+', line_stripped)]\n",
    "            # Remove leading empty element if exists\n",
    "            if row and row[0] == \"\":\n",
    "                row = row[1:]\n",
    "            # If we have a header and the \"Short Text\" column, and there are extra fields,\n",
    "            # combine extra fields into the \"Short Text\" column.\n",
    "            if expected_columns and short_text_index is not None and len(row) > expected_columns:\n",
    "                extra = len(row) - expected_columns\n",
    "                # Combine the fields that belong to \"Short Text\"\n",
    "                combined = \"|\".join(row[short_text_index:short_text_index + extra + 1])\n",
    "                # Build the new row: before Short Text, then combined field, then the rest\n",
    "                row = row[:short_text_index] + [combined] + row[short_text_index + extra + 1:]\n",
    "            # Only add the row if it contains data\n",
    "            if row and any(field for field in row):\n",
    "                rows.append(row)\n",
    "\n",
    "# --- Deduplicate Columns: Remove duplicate headers and corresponding values ---\n",
    "if rows:\n",
    "    header = rows[0]\n",
    "    seen = {}\n",
    "    duplicate_indices = []\n",
    "    new_header = []\n",
    "    for idx, col in enumerate(header):\n",
    "        if col not in seen:\n",
    "            seen[col] = idx\n",
    "            new_header.append(col)\n",
    "        else:\n",
    "            duplicate_indices.append(idx)\n",
    "    # Replace header row with the deduplicated header\n",
    "    rows[0] = new_header\n",
    "    # Remove duplicate columns from every subsequent row.\n",
    "    # Sorting in descending order to avoid index shifting.\n",
    "    duplicate_indices = sorted(duplicate_indices, reverse=True)\n",
    "    for i in range(1, len(rows)):\n",
    "        row = rows[i]\n",
    "        for idx in duplicate_indices:\n",
    "            if idx < len(row):\n",
    "                row.pop(idx)\n",
    "\n",
    "# with open(\"jandataagain.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as outfile:\n",
    "#     writer = csv.writer(outfile)\n",
    "#     writer.writerows(rows)\n",
    "\n",
    "# print(\"CSV conversion complete. 'output.csv' has been created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8706a0-1d0c-4ade-8a7c-f8ee669db9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Concate Different month data after conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "971f6e76-a26f-4602-8ea6-5e76f5462bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HIMANSHU SURYAVANSHI\\AppData\\Local\\Temp\\ipykernel_13504\\3674807392.py:6: DtypeWarning: Columns (14,15,21,22,23,24,25,26,31,33,49,50,55,56,66,69,70,71,74,75) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_list = [pd.read_csv(file) for file in files]\n",
      "C:\\Users\\HIMANSHU SURYAVANSHI\\AppData\\Local\\Temp\\ipykernel_13504\\3674807392.py:6: DtypeWarning: Columns (2,14,15,24,31,33,49,50,55,56,66,69,70,71,75) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_list = [pd.read_csv(file) for file in files]\n",
      "C:\\Users\\HIMANSHU SURYAVANSHI\\AppData\\Local\\Temp\\ipykernel_13504\\3674807392.py:6: DtypeWarning: Columns (14,15,23,24,25,26,31,33,49,50,55,56,66,69,70,71,74,75) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_list = [pd.read_csv(file) for file in files]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All monthly data has been successfully concatenated into 'final_concatenated_output.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "files = [\"EKPO_Jan24.csv\", \"EKPO_Feb24.csv\", \"EKPO_Mar24.csv\"]\n",
    "\n",
    "df_list = [pd.read_csv(file) for file in files]\n",
    "\n",
    "final_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "final_df.to_csv(\"final_concatenated_output.csv\", index=False)\n",
    "\n",
    "print(\"All monthly data has been successfully concatenated into 'final_concatenated_output.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a8228b-0196-46b5-99f5-b75a6c8bfe0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
